{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"v3kIY2MOoQ0h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672210742987,"user_tz":-180,"elapsed":80219,"user":{"displayName":"fares ghazzawi","userId":"01218365662380938928"}},"outputId":"3188d271-54cb-4c23-e9e5-fbcf6e9aa942"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","source":["%cd drive/MyDrive/ExamProject"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yKtKEA9Wi4lO","executionInfo":{"status":"ok","timestamp":1672210742988,"user_tz":-180,"elapsed":62,"user":{"displayName":"fares ghazzawi","userId":"01218365662380938928"}},"outputId":"434f5ecc-4698-4480-e581-d397521a3e36"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ExamProject\n"]}]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oCPXq-Bai55Y","executionInfo":{"status":"ok","timestamp":1672210743526,"user_tz":-180,"elapsed":587,"user":{"displayName":"fares ghazzawi","userId":"01218365662380938928"}},"outputId":"52820c32-6090-4f78-f69b-dd851232144d"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":[" archive.zip\t\t\t'PASCAL_VOC (1)'\n"," augmentations_examples.ipynb\t __pycache__\n"," augmentations_examples.py\t Test.ipynb\n"," dataset\t\t\t Training.ipynb\n"," DataSet.py\t\t\t Weights\n"," helper_functions.ipynb\t\t YOLO_DataSet.ipynb\n"," helper_functions.py\t\t yolo_dataset.py\n"," intersection_over_union.ipynb\t YoloV1_the_model.ipynb\n"," intersection_over_union.py\t yolov1_the_model.py\n"," mean_average_precision.ipynb\t'YOLOv3 Intermidiate status report.pptx'\n"," MeanAveragePrecision.ipynb\t YOLOv3_loss_function.ipynb\n"," mean_average_precision.py\t yolov3_loss_function.py\n"," MeanAveragePrecision.py\t YOLOV3_the_model.ipynb\n"," my_checkpoint.pth.tar\t\t YOLOV3_the_model.py\n"," Non_Max_Suppression.ipynb\t'YOLOV3_the_model - withPreTrainedWeight.ipynb'\n"," non_max_suppression.py\t\t yolov3_the_model_withpretrainedweight.py\n"," PASCAL_VOC\n"]}]},{"cell_type":"code","source":["from yolov3_the_model_withpretrainedweight import YOLOv3\n","from yolo_dataset import YOLODataset\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","import cv2\n","import torch\n","from torch.utils.data import DataLoader\n","from helper_functions import plot_couple_examples"],"metadata":{"id":"QHF_OSHwi9CD","executionInfo":{"status":"ok","timestamp":1672210751411,"user_tz":-180,"elapsed":7896,"user":{"displayName":"fares ghazzawi","userId":"01218365662380938928"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"988ddba1-3490-4f5d-e432-74b737bece28"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0.1020, 0.3021, 0.7511, 0.0174, 0.0273, 0.0673, 0.0010, 0.0046, 0.0080])\n"]}]},{"cell_type":"code","source":["DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","ANCHORS = [\n","    [(0.28, 0.22), (0.38, 0.48), (0.9, 0.78)],\n","    [(0.07, 0.15), (0.15, 0.11), (0.14, 0.29)],\n","    [(0.02, 0.03), (0.04, 0.07), (0.08, 0.06)],\n","] \n","DATASET = 'PASCAL_VOC'\n","IMAGE_SIZE = 416\n","scale = 1.1\n","IMG_DIR = DATASET + \"/images/\"\n","LABEL_DIR = DATASET + \"/labels/\"\n","NUM_WORKERS = 4\n","BATCH_SIZE = 32\n","PIN_MEMORY = True\n","S = [IMAGE_SIZE // 32, IMAGE_SIZE // 16, IMAGE_SIZE // 8] #13 26 52\n","NUM_EPOCHS = 10\n","\n","PASCAL_CLASSES = [\n","    \"aeroplane\",\n","    \"bicycle\",\n","    \"bird\",\n","    \"boat\",\n","    \"bottle\",\n","    \"bus\",\n","    \"car\",\n","    \"cat\",\n","    \"chair\",\n","    \"cow\",\n","    \"diningtable\",\n","    \"dog\",\n","    \"horse\",\n","    \"motorbike\",\n","    \"person\",\n","    \"pottedplant\",\n","    \"sheep\",\n","    \"sofa\",\n","    \"train\",\n","    \"tvmonitor\"\n","]\n"],"metadata":{"id":"DkI0qEvClfXY","executionInfo":{"status":"ok","timestamp":1672210752385,"user_tz":-180,"elapsed":986,"user":{"displayName":"fares ghazzawi","userId":"01218365662380938928"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["train_transforms = A.Compose(\n","    [\n","        A.LongestMaxSize(max_size=int(IMAGE_SIZE * scale)),\n","        A.PadIfNeeded(\n","            min_height=int(IMAGE_SIZE * scale),\n","            min_width=int(IMAGE_SIZE * scale),\n","            border_mode=cv2.BORDER_CONSTANT,\n","        ),\n","        A.RandomCrop(width=IMAGE_SIZE, height=IMAGE_SIZE),\n","        A.ColorJitter(brightness=0.6, contrast=0.6, saturation=0.6, hue=0.6, p=0.4),\n","        A.OneOf(\n","            [\n","                A.ShiftScaleRotate(\n","                    rotate_limit=10, p=0.4, border_mode=cv2.BORDER_CONSTANT\n","                ),\n","                A.IAAAffine(shear=10, p=0.4, mode=\"constant\"),\n","            ],\n","            p=1.0,\n","        ),\n","        A.HorizontalFlip(p=0.5),\n","        A.Blur(p=0.1),\n","        A.CLAHE(p=0.1),\n","        A.Posterize(p=0.1),\n","        A.ToGray(p=0.1),\n","        A.ChannelShuffle(p=0.05),\n","        A.Normalize(mean=[0, 0, 0], std=[1, 1, 1], max_pixel_value=255,),\n","        ToTensorV2(),\n","    ],\n","    bbox_params=A.BboxParams(format=\"yolo\", min_visibility=0.4, label_fields=[],),\n",")\n","test_transforms = A.Compose(\n","    [\n","        A.LongestMaxSize(max_size=IMAGE_SIZE),\n","        A.PadIfNeeded(\n","            min_height=IMAGE_SIZE, min_width=IMAGE_SIZE, border_mode=cv2.BORDER_CONSTANT\n","        ),\n","        A.Normalize(mean=[0, 0, 0], std=[1, 1, 1], max_pixel_value=255,),\n","        ToTensorV2(),\n","    ],\n","    bbox_params=A.BboxParams(format=\"yolo\", min_visibility=0.4, label_fields=[]),\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_-JOQ-8DlYMy","executionInfo":{"status":"ok","timestamp":1672210752387,"user_tz":-180,"elapsed":17,"user":{"displayName":"fares ghazzawi","userId":"01218365662380938928"}},"outputId":"9ea6fe9e-a6ec-4cc1-a76b-addb86643b62"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/albumentations/imgaug/transforms.py:348: FutureWarning: This IAAAffine is deprecated. Please use Affine instead\n","  warnings.warn(\"This IAAAffine is deprecated. Please use Affine instead\", FutureWarning)\n"]}]},{"cell_type":"code","source":["# #import albumentations as A\n","# #import cv2\n","# #from albumentations.pytorch import ToTensorV2\n","# #import matplotlib.pyplot as plt\n","# #import matplotlib.patches as patches\n","# import numpy as np\n","# import os\n","# import random\n","# import torch\n","# #from collections import Counter\n","# from torch.utils.data import DataLoader\n","# from tqdm import tqdm\n","# #from intersection_over_union import intersection_over_union , intersection_over_union_wh\n","# #from mean_average_precision import mean_average_precision\n","# #from non_max_suppression import nms\n","# from tqdm import tqdm\n","# ## import the utils\n","# #from yolov3_loss_function import Yolov3Loss\n","# #from yolo_dataset import YOLODataset"],"metadata":{"id":"52xSrpeSlKaj","executionInfo":{"status":"ok","timestamp":1672210752388,"user_tz":-180,"elapsed":15,"user":{"displayName":"fares ghazzawi","userId":"01218365662380938928"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["model = YOLOv3(num_classes = 20).to(DEVICE)"],"metadata":{"id":"SIZKAsz_jSle","executionInfo":{"status":"ok","timestamp":1672210756877,"user_tz":-180,"elapsed":4503,"user":{"displayName":"fares ghazzawi","userId":"01218365662380938928"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["checkpoint = torch.load(\"Weights/PASCAL.StateDictionary.tar\", map_location=DEVICE)\n","model.load_state_dict(checkpoint[\"state_dict\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mtIvVfRUaOlL","executionInfo":{"status":"ok","timestamp":1672210775460,"user_tz":-180,"elapsed":18589,"user":{"displayName":"fares ghazzawi","userId":"01218365662380938928"}},"outputId":"bb4fc00d-73de-48eb-fd7e-5a414ca8a48d"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["#model.load_darknet_weights(weights_path=\"Weights/yolov3.weights\")"],"metadata":{"id":"AKVrNgcJkgJE","executionInfo":{"status":"ok","timestamp":1672210775462,"user_tz":-180,"elapsed":29,"user":{"displayName":"fares ghazzawi","userId":"01218365662380938928"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def get_loaders(train_csv_path, test_csv_path):\n","    #from yolo_dataset import YOLODataset\n","    IMAGE_SIZE = 416\n","    train_dataset = YOLODataset(\n","        train_csv_path,\n","        transform=train_transforms,\n","        S=[IMAGE_SIZE // 32, IMAGE_SIZE // 16, IMAGE_SIZE // 8],\n","        img_dir=IMG_DIR,\n","        label_dir=LABEL_DIR,\n","        anchors=ANCHORS,\n","    )\n","    test_dataset = YOLODataset(\n","        test_csv_path,\n","        transform= test_transforms,\n","        S=[IMAGE_SIZE // 32, IMAGE_SIZE // 16, IMAGE_SIZE // 8],\n","        img_dir=IMG_DIR,\n","        label_dir=LABEL_DIR,\n","        anchors=ANCHORS,\n","    )\n","    \n","    #train_loader = DataLoader(dataset=train_dataset, batch_size=1, shuffle=True)\n","    train_loader = DataLoader(\n","        dataset=train_dataset,\n","        batch_size=BATCH_SIZE,\n","        num_workers=NUM_WORKERS,\n","        pin_memory=PIN_MEMORY,\n","        shuffle=False,\n","        drop_last=False,\n","    )\n","    test_loader = DataLoader(\n","        dataset=test_dataset,\n","        batch_size=BATCH_SIZE,\n","        num_workers=NUM_WORKERS,\n","        pin_memory=PIN_MEMORY,\n","        shuffle=False,\n","        drop_last=False,\n","    )\n","\n","    train_eval_dataset = YOLODataset(\n","        train_csv_path,\n","        transform=test_transforms,\n","        S=[IMAGE_SIZE // 32, IMAGE_SIZE // 16, IMAGE_SIZE // 8],\n","        img_dir=IMG_DIR,\n","        label_dir=LABEL_DIR,\n","        anchors=ANCHORS,\n","    )\n","    train_eval_loader = DataLoader(\n","        dataset=train_eval_dataset,\n","        batch_size=BATCH_SIZE,\n","        num_workers=NUM_WORKERS,\n","        pin_memory=PIN_MEMORY,\n","        shuffle=False,\n","        drop_last=False,\n","    )\n","\n","    return train_loader, test_loader, train_eval_loader"],"metadata":{"id":"HG24mQF9kiyu","executionInfo":{"status":"ok","timestamp":1672210775464,"user_tz":-180,"elapsed":27,"user":{"displayName":"fares ghazzawi","userId":"01218365662380938928"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["train_loader, test_loader, train_eval_loader = get_loaders(\n","        train_csv_path=DATASET + \"/100examples.csv\", test_csv_path=DATASET + \"/100examples.csv\"\n","    )"],"metadata":{"id":"edSRi5wVmUfN","executionInfo":{"status":"ok","timestamp":1672210776420,"user_tz":-180,"elapsed":981,"user":{"displayName":"fares ghazzawi","userId":"01218365662380938928"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"94d2ac33-29ed-442c-f7a0-2d0a86ea633d"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}]},{"cell_type":"code","source":["scaled_anchors = (\n","        torch.tensor(ANCHORS)\n","        * torch.tensor(S).unsqueeze(1).unsqueeze(1).repeat(1, 3, 2)\n","    ).to(DEVICE)"],"metadata":{"id":"4eIdDpN7nD1Y","executionInfo":{"status":"ok","timestamp":1672210776421,"user_tz":-180,"elapsed":18,"user":{"displayName":"fares ghazzawi","userId":"01218365662380938928"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["###### helper functions"],"metadata":{"id":"0dkjT7ZkZjKZ"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import torch\n","from tqdm import tqdm\n","from non_max_suppression import nms\n","import numpy as np\n","import matplotlib.patches as patches"],"metadata":{"id":"eaORaKzyZrS3","executionInfo":{"status":"ok","timestamp":1672210776421,"user_tz":-180,"elapsed":16,"user":{"displayName":"fares ghazzawi","userId":"01218365662380938928"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def cells_to_bboxes(predictions, anchors, S, is_preds=True):\n","    \"\"\"\n","    Scales the predictions coming from the model to\n","    be relative to the entire image such that they for example later\n","    can be plotted or.\n","    INPUT:\n","    predictions: tensor of size (N, 3, S, S, num_classes+5)\n","    anchors: the anchors used for the predictions\n","    S: the number of cells the image is divided in on the width (and height)\n","    is_preds: whether the input is predictions or the true bounding boxes\n","    OUTPUT:\n","    converted_bboxes: the converted boxes of sizes (N, num_anchors, S, S, 1+5) with class index,\n","                      object score, bounding box coordinates\n","    \"\"\"\n","    BATCH_SIZE = predictions.shape[0]\n","    num_anchors = len(anchors)\n","    box_predictions = predictions[..., 1:5]\n","    if is_preds:\n","        anchors = anchors.reshape(1, len(anchors), 1, 1, 2)\n","        box_predictions[..., 0:2] = torch.sigmoid(box_predictions[..., 0:2])\n","        box_predictions[..., 2:] = torch.exp(box_predictions[..., 2:]) * anchors\n","        scores = torch.sigmoid(predictions[..., 0:1])\n","        best_class = torch.argmax(predictions[..., 5:], dim=-1).unsqueeze(-1)\n","    else:\n","        scores = predictions[..., 0:1]\n","        best_class = predictions[..., 5:6]\n","\n","    cell_indices = (\n","        torch.arange(S)\n","        .repeat(predictions.shape[0], 3, S, 1)\n","        .unsqueeze(-1)\n","        .to(predictions.device)\n","    )\n","    x = 1 / S * (box_predictions[..., 0:1] + cell_indices)\n","    y = 1 / S * (box_predictions[..., 1:2] + cell_indices.permute(0, 1, 3, 2, 4))\n","    w_h = 1 / S * box_predictions[..., 2:4]\n","    converted_bboxes = torch.cat((best_class, scores, x, y, w_h), dim=-1).reshape(BATCH_SIZE, num_anchors * S * S, 6)\n","    return converted_bboxes.tolist()"],"metadata":{"id":"Ryys7Z45ZiOn","executionInfo":{"status":"ok","timestamp":1672210776424,"user_tz":-180,"elapsed":18,"user":{"displayName":"fares ghazzawi","userId":"01218365662380938928"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def plot_image(image, boxes):\n","    \"\"\"Plots predicted bounding boxes on the image\"\"\"\n","    cmap = plt.get_cmap(\"tab20b\")\n","    #change this to \n","    class_labels = PASCAL_CLASSES\n","    \n","    colors = [cmap(i) for i in np.linspace(0, 1, len(class_labels))]\n","    im = np.array(image)\n","    height, width, _ = im.shape\n","\n","    # Create figure and axes\n","    fig, ax = plt.subplots(1)\n","    # Display the image\n","    ax.imshow(im,aspect='auto')\n","\n","    # box[0] is x midpoint, box[2] is width\n","    # box[1] is y midpoint, box[3] is height\n","\n","    # Create a Rectangle patch\n","    for box in boxes:\n","        assert len(box) == 6, \"box should contain class pred, confidence, x, y, width, height\"\n","        class_pred = box[0]\n","        box = box[2:]\n","        upper_left_x = box[0] - box[2] / 2\n","        upper_left_y = box[1] - box[3] / 2\n","        rect = patches.Rectangle(\n","            (upper_left_x * width, upper_left_y * height),\n","            box[2] * width,\n","            box[3] * height,\n","            linewidth=2,\n","            edgecolor=colors[int(class_pred)],\n","            facecolor=\"none\",\n","        )\n","        # Add the patch to the Axes\n","        ax.add_patch(rect)\n","        plt.text(\n","            upper_left_x * width,\n","            upper_left_y * height,\n","            s=class_labels[int(class_pred)],\n","            color=\"white\",\n","            verticalalignment=\"top\",\n","            bbox={\"color\": colors[int(class_pred)], \"pad\": 0},\n","        )\n","\n","    plt.show()\n"],"metadata":{"id":"6t20uT6IZw2_","executionInfo":{"status":"ok","timestamp":1672210776425,"user_tz":-180,"elapsed":17,"user":{"displayName":"fares ghazzawi","userId":"01218365662380938928"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def plot_couple_examples(model, loader, thresh, iou_thresh, anchors):\n","    model.eval()\n","    x, y = next(iter(loader))\n","    x = x.to(\"cuda\")\n","    with torch.no_grad():\n","        out = model(x)\n","        bboxes = [[] for _ in range(x.shape[0])]\n","        for i in range(3):\n","            batch_size, A, S, _, _ = out[i].shape\n","            anchor = anchors[i]\n","            boxes_scale_i = cells_to_bboxes(\n","                out[i], anchor, S=S, is_preds=True\n","            )\n","            for idx, (box) in enumerate(boxes_scale_i):\n","                bboxes[idx] += box\n","\n","        model.train()\n","\n","    for i in range(batch_size):\n","        nms_boxes = nms(\n","            bboxes[i], iou_threshold=iou_thresh, threshold=thresh, box_format=\"midpoint\",\n","        )\n","        plot_image(x[i].permute(1,2,0).detach().cpu(), nms_boxes)"],"metadata":{"id":"wxQpin7cZcrg","executionInfo":{"status":"ok","timestamp":1672210776427,"user_tz":-180,"elapsed":16,"user":{"displayName":"fares ghazzawi","userId":"01218365662380938928"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["####### main"],"metadata":{"id":"3PoyxpZwZmQm"}},{"cell_type":"code","source":["for epoch in range(NUM_EPOCHS):\n","  plot_couple_examples(model, test_loader, 0.6, 0.5, scaled_anchors)\n","  break\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":644},"id":"qZbWq9s8md3m","executionInfo":{"status":"error","timestamp":1672210777867,"user_tz":-180,"elapsed":1455,"user":{"displayName":"fares ghazzawi","userId":"01218365662380938928"}},"outputId":"5572e546-5250-4572-ef00-5a38f10f42a9"},"execution_count":18,"outputs":[{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-f9c5e9b3f208>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mplot_couple_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaled_anchors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-17-4fb8351f0061>\u001b[0m in \u001b[0;36mplot_couple_examples\u001b[0;34m(model, loader, thresh, iou_thresh, anchors)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_couple_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miou_thresh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manchors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1331\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1333\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1357\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1360\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: Caught OSError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\", line 58, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\", line 58, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/content/drive/MyDrive/ExamProject/yolo_dataset.py\", line 61, in __getitem__\n    bboxes = np.roll(np.loadtxt(fname=label_path, delimiter=\" \", ndmin=2), 4, axis=1).tolist() # [x,y,w,h,c]\n  File \"/usr/local/lib/python3.8/dist-packages/numpy/lib/npyio.py\", line 1067, in loadtxt\n    fh = np.lib._datasource.open(fname, 'rt', encoding=encoding)\n  File \"/usr/local/lib/python3.8/dist-packages/numpy/lib/_datasource.py\", line 193, in open\n    return ds.open(path, mode, encoding=encoding, newline=newline)\n  File \"/usr/local/lib/python3.8/dist-packages/numpy/lib/_datasource.py\", line 533, in open\n    raise IOError(\"%s not found.\" % path)\nOSError: PASCAL_VOC/labels/000007.txt not found.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"SWSAxmauhi3g"},"execution_count":null,"outputs":[]}]}